{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5rc1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kiksecret/Basic_Tensorflow/blob/main/TensorFlow_for_Image_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX8mhOLljYeM"
      },
      "source": [
        "# Basic TensorFlow for Image Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3KzJyjv3rnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7a7d53-f190-465d-e906-8b8d5755ca35"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmxkHFpt31bM"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTdRgExe4TRB"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN-eYjeYsfpk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4372cb-519d-40ed-b866-40dfd527ee9b"
      },
      "source": [
        "np.unique(training_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPc9d3gJ3jWF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "df222bb4-7a58-414c-dfa6-16699dbc2a93"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[1])\n",
        "print(training_labels[1])\n",
        "print(training_images[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[[  0   0   0   0   0   1   0   0   0   0  41 188 103  54  48  43  87 168 133  16   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0  49 136 219 216 228 236 255 255 255 255 217 215 254 231 160  45   0   0   0   0   0]\n",
            " [  0   0   0   0   0  14 176 222 224 212 203 198 196 200 215 204 202 201 201 201 209 218 224 164   0   0   0   0]\n",
            " [  0   0   0   0   0 188 219 200 198 202 198 199 199 201 196 198 198 200 200 200 200 201 200 225  41   0   0   0]\n",
            " [  0   0   0   0  51 219 199 203 203 212 238 248 250 245 249 246 247 252 248 235 207 203 203 222 140   0   0   0]\n",
            " [  0   0   0   0 116 226 206 204 207 204 101  75  47  73  48  50  45  51  63 113 222 202 206 220 224   0   0   0]\n",
            " [  0   0   0   0 200 222 209 203 215 200   0  70  98   0 103  59  68  71  49   0 219 206 214 210 250  38   0   0]\n",
            " [  0   0   0   0 247 218 212 210 215 214   0 254 243 139 255 174 251 255 205   0 215 217 214 208 220  95   0   0]\n",
            " [  0   0   0  45 226 214 214 215 224 205   0  42  35  60  16  17  12  13  70   0 189 216 212 206 212 156   0   0]\n",
            " [  0   0   0 164 235 214 211 220 216 201  52  71  89  94  83  78  70  76  92  87 206 207 222 213 219 208   0   0]\n",
            " [  0   0   0 106 187 223 237 248 211 198 252 250 248 245 248 252 253 250 252 239 201 212 225 215 193 113   0   0]\n",
            " [  0   0   0   0   0  17  54 159 222 193 208 192 197 200 200 200 200 201 203 195 210 165   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  47 225 192 214 203 206 204 204 205 206 204 212 197 218 107   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   6   0  46 212 195 212 202 206 205 204 205 206 204 212 200 218  91   0   3   1   0   0   0]\n",
            " [  0   0   0   0   0   1   0  11 197 199 205 202 205 206 204 205 207 204 205 205 218  77   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   3   0   2 191 198 201 205 206 205 205 206 209 206 199 209 219  74   0   5   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   0 188 197 200 207 207 204 207 207 210 208 198 207 221  72   0   4   0   0   0   0]\n",
            " [  0   0   0   0   0   2   0   0 215 198 203 206 208 205 207 207 210 208 200 202 222  75   0   4   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 212 198 209 206 209 206 208 207 211 206 205 198 221  80   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 204 201 205 208 207 205 211 205 210 210 209 195 221  96   0   3   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 202 201 205 209 207 205 213 206 210 209 210 194 217 105   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 204 204 205 208 207 205 215 207 210 208 211 193 213 115   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 204 207 207 208 206 206 215 210 210 207 212 195 210 118   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 198 208 208 208 204 207 212 212 210 207 211 196 207 121   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 198 210 207 208 206 209 213 212 211 207 210 197 207 124   0   1   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 172 210 203 201 199 204 207 205 204 201 205 197 206 127   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 188 221 214 234 236 238 244 244 244 240 243 214 224 162   0   2   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0 139 146 130 135 135 137 125 124 125 121 119 114 130  76   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRH19pWs6ZDn"
      },
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mAyndG3kVlK"
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                     \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lUcWaiX7MFj"
      },
      "source": [
        "โดยที่\n",
        "**Sequential**: ใช้กำหนดชั้น (Layer) แบบ SEQUENCE ใน ANN\n",
        "\n",
        "**Flatten**: หมายถึงการนำข้อมูล 2D ของรูปภาพมาทำเรียงต่อกันให้เป็น 1D\n",
        "\n",
        "**Dense**: ใน Deep Learning เราสามารถเพิ่มชั้นได้เรื่อยๆ โดยกำหนดให้มีจำนวนนิวรอน (Neuron) ได้ตามต้องการ เช่น 128 และ 10 เป็นต้น โปรดสังเกต ในกรณีนี้ ชั้นสุดท้ายมีจำนวนนิวรอนเป็น 10 ตามจำนวนกลุ่มของเอาท์พุตที่ต้องการ 0 - 9\n",
        "\n",
        "แต่ละชั้นจำเป็นต้องใช้ **activation function** เช่น\n",
        "\n",
        "**Relu** หมายถึง \"If X>0 return X, else return 0\" ให้ผลลัพธ์เป็น X หาก X มีค่าเป็นบวก หรือไม่ให้ค่าเป็น 0 หาก X เท่ากับหรือน้อยกว่า 0\n",
        "\n",
        "**Softmax** เป็นการหาค่าสูงสุดในลิสต์ เช่น หากอินพุตของชั้นนี้เป็น [0.1, 0.1, 0.05, 0.1, 0.95, 0.1, 0.05, 0.05, 0.05] ฟังก์ชันนี้จะให้ค่าเอาท์พุตเป็น [0,0,0,0,1,0,0,0,0] ทำให้สามารถระบุว่า การคัดแยกกลุ่ม (Classification) ของภาพอยู่ในกลุ่มใด\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLMdl9aP8nQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb1577e8-f3c1-4945-86a4-0ccc4676429c"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4940 - accuracy: 0.8262\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3680 - accuracy: 0.8666\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3330 - accuracy: 0.8778\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3108 - accuracy: 0.8854\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2916 - accuracy: 0.8915\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fae0d0d84d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzlqsEzX9s5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdeb6d7-56d2-453c-c205-0396259698dd"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3595 - accuracy: 0.8762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.359540194272995, 0.8762000203132629]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyEIki0z_hAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c04a18-f620-423c-ac26-ef9cddc41030"
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.5122413e-05 6.5254660e-08 6.6215085e-07 4.4252914e-08 3.0005381e-07 1.6324235e-02 5.0615931e-06 1.6579565e-02 2.8281111e-06 9.6707201e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnBGOrMiA1n5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f13d41b8-b73d-403e-c526-596e1c04701a"
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DObcsHVjKgQ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf923054-7537-46f0-facb-a141b65e969d"
      },
      "source": [
        "np.set_printoptions(linewidth=200)\n",
        "plt.imshow(test_images[0])\n",
        "print(test_images[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.01176471 0.00392157 0.         0.         0.02745098 0.         0.14509804 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.00784314 0.         0.10588235\n",
            "  0.32941176 0.04313725 0.         0.         0.         0.         0.         0.         0.46666667 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.         0.34509804\n",
            "  0.56078431 0.43137255 0.         0.         0.         0.         0.08627451 0.36470588 0.41568627 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01568627 0.         0.20784314 0.50588235\n",
            "  0.47058824 0.57647059 0.68627451 0.61568627 0.65098039 0.52941176 0.60392157 0.65882353 0.54901961 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00784314 0.         0.04313725 0.5372549  0.50980392\n",
            "  0.50196078 0.62745098 0.69019608 0.62352941 0.65490196 0.69803922 0.58431373 0.59215686 0.56470588 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.00392157 0.         0.00784314 0.00392157 0.         0.01176471 0.         0.         0.45098039 0.44705882 0.41568627\n",
            "  0.5372549  0.65882353 0.6        0.61176471 0.64705882 0.65490196 0.56078431 0.61568627 0.61960784 0.04313725 0.        ]\n",
            " [0.         0.         0.         0.         0.00392157 0.         0.         0.         0.         0.         0.01176471 0.         0.         0.34901961 0.54509804 0.35294118 0.36862745\n",
            "  0.6        0.58431373 0.51372549 0.59215686 0.6627451  0.6745098  0.56078431 0.62352941 0.6627451  0.18823529 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.00784314 0.01568627 0.00392157 0.         0.         0.         0.38431373 0.53333333 0.43137255 0.42745098 0.43137255\n",
            "  0.63529412 0.52941176 0.56470588 0.58431373 0.62352941 0.65490196 0.56470588 0.61960784 0.6627451  0.46666667 0.        ]\n",
            " [0.         0.         0.00784314 0.00784314 0.00392157 0.00784314 0.         0.         0.         0.         0.10196078 0.42352941 0.45882353 0.38823529 0.43529412 0.45882353 0.53333333\n",
            "  0.61176471 0.5254902  0.60392157 0.60392157 0.61176471 0.62745098 0.55294118 0.57647059 0.61176471 0.69803922 0.        ]\n",
            " [0.01176471 0.         0.         0.         0.         0.         0.         0.08235294 0.20784314 0.36078431 0.45882353 0.43529412 0.40392157 0.45098039 0.50588235 0.5254902  0.56078431\n",
            "  0.60392157 0.64705882 0.66666667 0.60392157 0.59215686 0.60392157 0.56078431 0.54117647 0.58823529 0.64705882 0.16862745]\n",
            " [0.         0.         0.09019608 0.21176471 0.25490196 0.29803922 0.33333333 0.4627451  0.50196078 0.48235294 0.43529412 0.44313725 0.4627451  0.49803922 0.49019608 0.54509804 0.52156863\n",
            "  0.53333333 0.62745098 0.54901961 0.60784314 0.63137255 0.56470588 0.60784314 0.6745098  0.63137255 0.74117647 0.24313725]\n",
            " [0.         0.26666667 0.36862745 0.35294118 0.43529412 0.44705882 0.43529412 0.44705882 0.45098039 0.49803922 0.52941176 0.53333333 0.56078431 0.49411765 0.49803922 0.59215686 0.60392157\n",
            "  0.56078431 0.58039216 0.49019608 0.63529412 0.63529412 0.56470588 0.54117647 0.6        0.63529412 0.76862745 0.22745098]\n",
            " [0.2745098  0.6627451  0.50588235 0.40784314 0.38431373 0.39215686 0.36862745 0.38039216 0.38431373 0.4        0.42352941 0.41568627 0.46666667 0.47058824 0.50588235 0.58431373 0.61176471\n",
            "  0.65490196 0.74509804 0.74509804 0.76862745 0.77647059 0.77647059 0.73333333 0.77254902 0.74117647 0.72156863 0.14117647]\n",
            " [0.0627451  0.49411765 0.67058824 0.7372549  0.7372549  0.72156863 0.67058824 0.6        0.52941176 0.47058824 0.49411765 0.49803922 0.57254902 0.7254902  0.76470588 0.81960784 0.81568627\n",
            "  1.         0.81960784 0.69411765 0.96078431 0.98823529 0.98431373 0.98431373 0.96862745 0.8627451  0.80784314 0.19215686]\n",
            " [0.         0.         0.         0.04705882 0.2627451  0.41568627 0.64313725 0.7254902  0.78039216 0.82352941 0.82745098 0.82352941 0.81568627 0.74509804 0.58823529 0.32156863 0.03137255\n",
            "  0.         0.         0.         0.69803922 0.81568627 0.7372549  0.68627451 0.63529412 0.61960784 0.59215686 0.04313725]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGnfOT5utFbO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a54cfe60-18db-4f02-8f31-3782811b417b"
      },
      "source": [
        "print(classifications[7])\n",
        "print(test_labels[7])\n",
        "\n",
        "np.set_printoptions(linewidth=200)\n",
        "plt.imshow(test_images[7])\n",
        "print(test_images[7])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.7185466e-10 3.7591181e-07 2.4194881e-06 1.1909655e-04 2.3746821e-03 3.3508570e-07 1.5990577e-11 2.2684713e-05 1.9980956e-08 9.9748045e-01]\n",
            "9\n",
            "[[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.05490196 0.58431373 0.75686275 0.01960784 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.35686275 0.87843137 0.99215686 0.99215686 0.0745098  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.10980392 0.92156863 0.99607843 0.99215686 0.99215686 0.65098039 0.07058824 0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.56470588 0.99215686 0.99607843 0.99215686 0.99215686 0.99215686 0.93333333 0.45098039\n",
            "  0.02352941 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.12156863 0.94509804 0.99215686 0.81568627 0.7254902  0.99215686 0.99215686 0.99215686 0.90588235\n",
            "  0.09411765 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.30980392 0.99607843 0.75686275 0.         0.03137255 0.38431373 0.85882353 0.99607843 1.\n",
            "  0.78823529 0.07058824 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.3372549  0.99215686 0.31372549 0.         0.         0.         0.71372549 0.99215686 0.99607843\n",
            "  0.74901961 0.04705882 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.68627451 0.99215686 0.60784314 0.         0.         0.         0.91764706 0.99215686 0.99607843\n",
            "  0.52941176 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.3372549  0.99215686 0.81568627 0.15686275 0.33333333 0.65098039 0.98431373 0.92941176 0.99607843\n",
            "  0.9254902  0.16470588 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.07058824 0.93333333 0.99215686 0.99607843 0.99215686 0.99215686 0.7254902  0.14117647 0.84705882\n",
            "  0.99215686 0.59607843 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.26666667 0.94117647 1.         0.99607843 0.56862745 0.03137255 0.         0.5254902\n",
            "  0.99607843 0.8745098  0.1372549  0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.26666667 0.61960784 0.55686275 0.04705882 0.         0.         0.03529412\n",
            "  0.68627451 0.99215686 0.63137255 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.34509804 0.99215686 0.88627451 0.07058824 0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.00784314 0.65098039 0.99215686 0.49411765 0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.18823529 0.96078431 0.99215686 0.14901961 0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.45098039 0.99607843 0.6745098  0.03529412 0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.08235294 0.85490196 0.99607843 0.18039216 0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.11764706 0.99607843 0.64705882 0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.72941176 0.95686275 0.16470588 0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.05490196 0.8745098  0.30588235 0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSZSwV5UObQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194a7053-1988-4f22-813b-ebd89b4537b5"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                     \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2018 - accuracy: 0.9405\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0806 - accuracy: 0.9754\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0519 - accuracy: 0.9841\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0367 - accuracy: 0.9881\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0276 - accuracy: 0.9917\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0788 - accuracy: 0.9760\n",
            "[2.7509997e-09 1.7764544e-08 1.5149682e-07 3.8235474e-05 2.4364023e-11 3.8879837e-09 3.6775821e-12 9.9996030e-01 2.6431672e-07 1.0622342e-06]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3luOX3WlSND",
        "outputId": "bdfbe425-c516-45d6-a2b7-fa07ead3ae68"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                     \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1853 - accuracy: 0.9444\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0743 - accuracy: 0.9765\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0490 - accuracy: 0.9847\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0342 - accuracy: 0.9888\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0258 - accuracy: 0.9916\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0713 - accuracy: 0.9798\n",
            "[1.3251903e-09 1.7413694e-08 1.2349695e-07 9.3349927e-06 3.4094331e-13 1.0198253e-09 3.3673846e-14 9.9999022e-01 1.8798325e-09 3.0758460e-07]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExNxCwhcQ18S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "5faa50d1-ecb0-422a-8195-113a565c0a94"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                     \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ceeb3bc2d0c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m               loss = 'sparse_categorical_crossentropy')\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1738, in sparse_categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5114, in sparse_categorical_crossentropy\n        labels=target, logits=output)\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMckVntcSPvo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "223aa0e4-6740-4954-8d76-f67f8be60346"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-417021286da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m               loss = 'sparse_categorical_crossentropy')\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Received a label value of 9 which is outside the valid range of [0, 5).  Label values: 2 9 6 1 2 3 8 7 8 2 5 2 1 6 3 1 4 2 8 5 5 2 3 2 6 1 4 5 3 1 6 0\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n (defined at /usr/local/lib/python3.7/dist-packages/keras/backend.py:5114)\n]] [Op:__inference_train_function_707]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:\nIn[0] sparse_categorical_crossentropy/Reshape_1 (defined at /usr/local/lib/python3.7/dist-packages/keras/backend.py:5109)\t\nIn[1] sparse_categorical_crossentropy/Reshape (defined at /usr/local/lib/python3.7/dist-packages/keras/backend.py:3561)\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n>>>     handler_func(fileobj, events)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n>>>     self._handle_recv()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n>>>     self._run_callback(callback, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n>>>     callback(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n>>>     return self.dispatch_shell(stream, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n>>>     handler(stream, idents, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n>>>     user_expressions, allow_stdin)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n>>>     if self.run_code(code, result):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-2-417021286da7>\", line 22, in <module>\n>>>     model.fit(training_images, training_labels, epochs=5)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n>>>     y, y_pred, sample_weight, regularization_losses=self.losses)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1738, in sparse_categorical_crossentropy\n>>>     y_true, y_pred, from_logits=from_logits, axis=axis)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5114, in sparse_categorical_crossentropy\n>>>     labels=target, logits=output)\n>>> "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1YPa6UhS8Es",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba866bc-5e8b-4949-f870-f9e15be241ec"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1850 - accuracy: 0.9435\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0790 - accuracy: 0.9752\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0573 - accuracy: 0.9822\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0439 - accuracy: 0.9864\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0327 - accuracy: 0.9892\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0673 - accuracy: 0.9819\n",
            "[8.1669990e-11 3.3289897e-08 1.4403008e-09 5.8459193e-10 4.5699755e-12\n",
            " 1.0329322e-12 1.0744898e-15 9.9999988e-01 1.1508107e-11 1.6459283e-07]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i3YUa3Xge83"
      },
      "source": [
        "### คำตอบ\n",
        "เมื่อทำการเพิ่มชั้นใหม่ที่มี 256 นิวรอน ทำให้ได้เวลาที่ใช้เพิ่มขึ้นเล็กน้อย แต่ได้ค่า Loss และค่า Accuracy ดีขึ้น  ซึ่งการเพิ่มนิวรอนทำให้ค่า loss ลดลงนั่นเอง\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS3vVkOgCDGZ"
      },
      "source": [
        "## Exercise 6: \n",
        "\n",
        "ทดลองการเทรนโมเดลโดยไม่ทำการ Normalization สังเกตผลลัพธ์ที่ได้\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDqNAqrpCNg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "777581ec-1ad9-40ec-f2a4-b73cef50306a"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# ยกเลิกการ Normalization ได้อย่างไร\n",
        "#training_images=training_images/255.0\n",
        "#test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 2.5791 - accuracy: 0.9075\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3306 - accuracy: 0.9364\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2870 - accuracy: 0.9417\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2715 - accuracy: 0.9440\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2358 - accuracy: 0.9488\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3007 - accuracy: 0.9409\n",
            "[1.5461132e-32 1.0468963e-11 3.5511551e-15 2.2880695e-09 3.5790599e-16\n",
            " 1.3901259e-13 1.3808530e-28 1.0000000e+00 9.1427090e-20 7.0758364e-12]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkaEHHgqZbYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4d52ab-c80f-48d8-94bf-edc21c1d7642"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss')<0.4):\n",
        "      print(\"\\nLoss < 40% so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4725 - accuracy: 0.8315\n",
            "Epoch 2/5\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.3594 - accuracy: 0.8689\n",
            "Loss < 40% so cancelling training!\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3595 - accuracy: 0.8688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88b08e0850>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aGHiMhnr14o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f3ceb3-db6e-42cd-cb2b-92e3034d6f60"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.85):\n",
        "      print(\"\\nAccuracy > 85% so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.4758 - accuracy: 0.8307\n",
            "Epoch 2/5\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.3580 - accuracy: 0.8686\n",
            "Accuracy > 85% so cancelling training!\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3580 - accuracy: 0.8686\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88b0a52490>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}